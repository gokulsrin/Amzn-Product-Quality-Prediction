{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/gokulsrin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4\n",
      "1         5\n",
      "2         5\n",
      "3         5\n",
      "4         5\n",
      "         ..\n",
      "111093    4\n",
      "111094    5\n",
      "111095    5\n",
      "111096    5\n",
      "111097    5\n",
      "Name: overall, Length: 111098, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn import *\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "import sklearn.model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "\n",
    "#1. USING PANDAS TO EXTRACT COLUMN DATA:\n",
    "#***************************************************************************\n",
    "df = pd.read_csv(\"../datasets/train.csv\")\n",
    "\n",
    "#array of all the summaries\n",
    "\n",
    "og_summaries = df['summary']\n",
    "summaries = df[\"summary\"]\n",
    "\n",
    "#array of the overalls\n",
    "overall = df[\"overall\"]\n",
    "print(overall)\n",
    "\n",
    "#array of product nums\n",
    "products = df[\"amazon-id\"]\n",
    "\n",
    "og_amazon_reviews = df['reviewText']\n",
    "amazon_reviews = df['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'str'>}\n",
      "Test accuracy: 81.57169744415046\n",
      "Time taken: 4.01 seconds\n",
      "{<class 'str'>}\n",
      "Test accuracy: 78.1272161911516\n",
      "Time taken: 1.31 seconds\n"
     ]
    }
   ],
   "source": [
    "# 2. CREATING SENTIMENT MODEL:\n",
    "#***************************************************************************\n",
    "#****2A. first creating sentiment model based on the amazon reviews\n",
    "\n",
    "# Using ratings associated with reviews as indicators of sentiment\n",
    "# i.e. turn any review with star rating >= 5 to 1, else 0 \n",
    "review_sentiments = [int(overall[i] >= 5) for i in range(len(overall))]\n",
    "\n",
    "\n",
    "for i in range(len(amazon_reviews)):\n",
    "    if type(amazon_reviews[i])!=str:\n",
    "        amazon_reviews.pop(i)\n",
    "        review_sentiments.pop(i)\n",
    "print(set([type(r) for r in amazon_reviews]))\n",
    "\n",
    "\n",
    "#create train test split\n",
    "x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(amazon_reviews, \n",
    "                                                                       review_sentiments, \n",
    "                                                                       random_state=1, test_size=0.33)\n",
    "#vectorize data \n",
    "vect1 = TfidfVectorizer()\n",
    "x_train = vect1.fit_transform(x_train)\n",
    "x_test = vect1.transform(x_test)\n",
    "\n",
    "# We can experiment with different numbers of max iterations\n",
    "# 100 iters is default\n",
    "# iters = [1000]\n",
    "\n",
    "start = time.time()\n",
    "review_clf = LogisticRegression(max_iter=500)\n",
    "review_clf.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Test accuracy: {}\".format(100*review_clf.score(x_test, y_test)))\n",
    "print(\"Time taken: {:.2f} seconds\".format(end-start))\n",
    "\n",
    "#****2B. first creating sentiment model based on the summary reviews\n",
    "summary_sentiments = [int(overall[i] >= 5) for i in range(len(overall))]\n",
    "for i in range(len(summaries)):\n",
    "    if type(summaries[i])!=str:\n",
    "        summaries.pop(i)\n",
    "        summary_sentiments.pop(i)\n",
    "print(set([type(s) for s in summaries]))\n",
    "\n",
    "#create train test split\n",
    "x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(summaries, \n",
    "                                                                       summary_sentiments, \n",
    "                                                                       random_state=1, test_size=0.33)\n",
    "\n",
    "# vectorize summary\n",
    "vect2 = TfidfVectorizer()\n",
    "x_train = vect2.fit_transform(x_train)\n",
    "x_test = vect2.transform(x_test)\n",
    "\n",
    "# We can experiment with different numbers of max iterations\n",
    "# 100 iters is default\n",
    "# iters = [1000]\n",
    "\n",
    "start = time.time()\n",
    "summary_clf = LogisticRegression(max_iter=500)\n",
    "summary_clf.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Test accuracy: {}\".format(100*summary_clf.score(x_test, y_test)))\n",
    "print(\"Time taken: {:.2f} seconds\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of summary sentiment classifier on Amazon summaries: 0.80\n",
      "Accuracy of review sentiment classifier on Amazon reviews: 0.84\n"
     ]
    }
   ],
   "source": [
    "#3. GENERATE AVERAGE PRODUCT REVIEW AND SUMMARY SENTIMENT:\n",
    "#***************************************************************************\n",
    "df = pd.read_csv(\"../datasets/train.csv\")\n",
    "\n",
    "# using models generated in (2) to determine average product review and summary sentiment\n",
    "\n",
    "summary_data = vect2.transform(df['summary'].values.astype('U'))\n",
    "review_data = vect1.transform(df['reviewText'].values.astype('U'))\n",
    "\n",
    "#predicting sentiment\n",
    "summary_predictions = summary_clf.predict(summary_data)\n",
    "review_predictions = review_clf.predict(review_data)\n",
    "\n",
    "#accuracy analysis\n",
    "def getAccuracy(texts, preds):\n",
    "    total = len(texts)\n",
    "    t = 0\n",
    "    for i in range(total):\n",
    "        if (overall[i] == 5 and preds[i] == 1) or (overall[i] != 5 and preds[i] == 0):\n",
    "            t+=1\n",
    "    return t/total\n",
    "\n",
    "#determine sentiment predictions\n",
    "print(\"Accuracy of summary sentiment classifier on Amazon summaries: {:.2f}\".format(getAccuracy(summaries, summary_predictions)))\n",
    "print(\"Accuracy of review sentiment classifier on Amazon reviews: {:.2f}\".format(getAccuracy(amazon_reviews, review_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. WE'LL NOW TRAIN SEVERAL CLASSIFIERS USING THE FOLLOWING FEATURES \n",
    "#***************************************************************************\n",
    "#   1.Using just avg. summary sentiment as a feature\n",
    "#   2. Using just avg. review sentiment as a feature\n",
    "#   3. Using avg. summary sentiment & avg. review sentiment\n",
    "#   4. Using avg. summary sentiment & avg. review sentiment & sales rank\n",
    "#   5. Using avg. summary sentiment & avg. review sentiment & salesrank & price\n",
    "\n",
    "\n",
    "#generate average review and summary sentiments\n",
    "targets = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in targets:\n",
    "        targets[products[i]] = [overall[i]]\n",
    "    else:\n",
    "        targets[products[i]].append(overall[i])\n",
    "\n",
    "targets = [int(np.average(targets[prod]) > 4.5) for prod in targets]\n",
    "\n",
    "review_predictions, summary_predictions = list(review_predictions), list(summary_predictions)\n",
    "\n",
    "amz_review_sentiments, amz_summary_sentiments = {}, {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in amz_review_sentiments:\n",
    "        amz_review_sentiments[products[i]] = [review_predictions[i]]\n",
    "        amz_summary_sentiments[products[i]] = [summary_predictions[i]]\n",
    "    else:\n",
    "        amz_review_sentiments[products[i]].append(review_predictions[i])\n",
    "        amz_summary_sentiments[products[i]].append(summary_predictions[i])\n",
    "\n",
    "\n",
    "avg_review_sentiments = [np.average(amz_review_sentiments[prod]) for prod in amz_review_sentiments]\n",
    "avg_summary_sentiments = [np.average(amz_summary_sentiments[prod]) for prod in amz_summary_sentiments]\n",
    "\n",
    "\n",
    "avg_review_sentiments = [[score] for score in avg_review_sentiments]\n",
    "avg_summary_sentiments = [[score] for score in avg_summary_sentiments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using summary sentiment only: 73.82\n"
     ]
    }
   ],
   "source": [
    "#PARADIGM 1: Just summary sentiments\n",
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(avg_summary_sentiments, targets, random_state=1)\n",
    "\n",
    "\n",
    "#train model\n",
    "summary_only_clf = LogisticRegression()\n",
    "summary_only_clf.fit(X_train, Y_train)\n",
    "print(\"Test accuracy using summary sentiment only: {:.2f}\".format(100*summary_only_clf.score(X_test, Y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using review sentiment only: 77.39\n"
     ]
    }
   ],
   "source": [
    "#PARADIGM 2: Just review sentiments\n",
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(avg_review_sentiments, targets, random_state=1)\n",
    "\n",
    "\n",
    "#train model\n",
    "review_only_clf = LogisticRegression()\n",
    "review_only_clf.fit(X_train, Y_train)\n",
    "print(\"Test accuracy using review sentiment only: {:.2f}\".format(100*review_only_clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using review sentiment and summary sentiment: 81.31\n",
      "Weighted F1 using review sentiment and summary sentiment: 81.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#PARADIGM 3: Just review & summary \n",
    "\n",
    "#create new feature matrix contraining avg. review and summary sentiment\n",
    "X = np.zeros((len(avg_review_sentiments), 2))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X[i] = (avg_review_sentiments[i][0], avg_summary_sentiments[i][0])\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "targets = [[t] for t in targets]\n",
    "\n",
    "targets = np.asarray(targets)\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "for train_idx, test_idx in kf.split(targets):\n",
    "    y_train, y_test = targets[train_idx], targets[test_idx]\n",
    "\n",
    "#train model\n",
    "review_and_summary_clf = LogisticRegression(C=0.6, class_weight={0:1.417, 1:1})\n",
    "review_and_summary_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Test accuracy using review sentiment and summary sentiment: {:.2f}\".format(100*review_and_summary_clf.score(X_test, y_test)))\n",
    "\n",
    "print(\"Weighted F1 using review sentiment and summary sentiment: {:.2f}\".format(100*f1_score(y_test, \n",
    "             review_and_summary_clf.predict(X_test), \n",
    "             average='weighted')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using review sentiment, summary sentiment, and sales rank: 81.21\n",
      "Weighted F1 using review sentiment, summary sentiment, and sales rank: 81.08\n",
      "Precision: 0.8237082066869301\n",
      "Recall: 0.8685897435897436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#PARADIGM 4: Just review & summary  & sales rank \n",
    "sales_ranks = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in sales_ranks:\n",
    "        sales_ranks[products[i]] = [df['salesRank'][i]]\n",
    "    else:\n",
    "        sales_ranks[products[i]].append(df['salesRank'][i])\n",
    "\n",
    "avg_sales_ranks = [[np.average(sales_ranks[prod])] for prod in sales_ranks]\n",
    "\n",
    "scaler = StandardScaler() # 73.6 weighted F1\n",
    "# scaler = MinMaxScaler() # 73.6 weighted F1\n",
    "# scaler = MaxAbsScaler() # 73.6 weighted F1\n",
    "# scaler = RobustScaler() # 73.6 weighted F1\n",
    "# scaler = Normalizer() # 73.48 weighted F1\n",
    "# scaler = QuantileTransformer() # 73.48 weighted F1\n",
    "# scaler = PowerTransformer() # 73.48 weighted F1\n",
    "\n",
    "scaler.fit(avg_sales_ranks)\n",
    "avg_sales_ranks = scaler.transform(avg_sales_ranks)\n",
    "\n",
    "X = np.zeros((len(avg_review_sentiments), 3))\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X[i] = (avg_review_sentiments[i][0], avg_summary_sentiments[i][0], avg_sales_ranks[i][0])\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "for train_idx, test_idx in kf.split(targets):\n",
    "    y_train, y_test = targets[train_idx], targets[test_idx]\n",
    "\n",
    "review_summary_sales_clf = LogisticRegression(C=0.1, class_weight={0:1.417, 1:1}, \n",
    "                                             tol=2)\n",
    "review_summary_sales_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test accuracy using review sentiment, summary sentiment, and sales rank: {:.2f}\".format(100*review_summary_sales_clf.score(X_test, y_test)))\n",
    "\n",
    "print(\"Weighted F1 using review sentiment, summary sentiment, and sales rank: {:.2f}\".format(100*f1_score(y_test, \n",
    "             review_summary_sales_clf.predict(X_test), \n",
    "             average='weighted')))\n",
    "\n",
    "# precision and recall \n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test, review_summary_sales_clf.predict(X_test), average='binary')\n",
    "print(\"Precision:\",precision)\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(y_test, review_summary_sales_clf.predict(X_test), average='binary')\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 using review sentiment, summary sentiment, sales rank, and price: 81.10\n",
      "Test accuracy using review sentiment, summary sentiment, sales rank, and price: 81.59\n",
      "Weighted F1 using review sentiment, summary sentiment, sales rank, and price: 81.54\n",
      "Weighted F1 using review sentiment, summary sentiment, sales rank, and price: 75.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 using review sentiment, summary sentiment, sales rank, and price: 71.14\n",
      "Weighted F1 using review sentiment, summary sentiment, sales rank, and price: 81.10\n"
     ]
    }
   ],
   "source": [
    "#PARADIGM 5: Just review & summary  & sales rank & prices\n",
    "\n",
    "#construct our price feature\n",
    "prices = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in prices:\n",
    "        prices[products[i]] = [df['price'][i]]\n",
    "    else:\n",
    "        prices[products[i]].append(df['price'][i])\n",
    "\n",
    "avg_prices = [[np.average(prices[prod])] for prod in prices]\n",
    "\n",
    "scaler.fit(avg_prices)\n",
    "avg_prices = scaler.transform(avg_prices)\n",
    "\n",
    "X = np.zeros((len(avg_review_sentiments), 4))\n",
    "for i in range(X.shape[0]):\n",
    "    X[i] = (avg_review_sentiments[i][0], avg_summary_sentiments[i][0], avg_sales_ranks[i][0], \n",
    "           avg_prices[i][0])\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "for train_idx, test_idx in kf.split(targets):\n",
    "    y_train, y_test = targets[train_idx], targets[test_idx]\n",
    "#begin testing models\n",
    "\n",
    "# LogReg\n",
    "review_summary_sales_price_clf = LogisticRegression(C=100, class_weight={0:1.417, 1:1}, solver='newton-cg')\n",
    "review_summary_sales_price_clf.fit(X_train, y_train)\n",
    "print(\"Weighted F1 using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*f1_score(y_test, \n",
    "             review_summary_sales_price_clf.predict(X_test), \n",
    "             average='weighted')))\n",
    "\n",
    "\n",
    "# SVM \n",
    "clf = svm.SVC(kernel='linear', class_weight ={0: 1.417, 1: 1})# Linear Kernel\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test accuracy using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*clf.score(X_test, y_test)))\n",
    "print(\"Weighted F1 using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*f1_score(y_test, \n",
    "             clf.predict(X_test), \n",
    "             average='weighted')))\n",
    "\n",
    "# #XGBOOST \n",
    "# from xgboost import XGBClassifier\n",
    "# review_summary_sales_price_clf = XGBClassifier() \n",
    "# review_summary_sales_price_clf.fit(X_train, y_train)\n",
    "# print(\"Test accuracy using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*review_summary_sales_price_clf.score(X_test, y_test)))\n",
    "\n",
    "# KNN\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Weighted F1 using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*f1_score(y_test, \n",
    "             classifier.predict(X_test), \n",
    "             average='weighted')))\n",
    "\n",
    "# decision tree\n",
    "classifier = DecisionTreeClassifier(class_weight ={0: 1.417, 1: 1})\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Weighted F1 using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*f1_score(y_test, \n",
    "             classifier.predict(X_test), \n",
    "             average='weighted')))\n",
    "\n",
    "# MLP NN\n",
    "clf = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Weighted F1 using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*f1_score(y_test, \n",
    "             clf.predict(X_test), \n",
    "             average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7de7a5ef5ba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# define dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# define models and parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.417\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msolvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# running grid search CV to find the best hyperparameters for LogReg\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# define dataset\n",
    "# define models and parameters\n",
    "model = LogisticRegression(class_weight={0: 1.417, 1: 1})\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.6, 0.3, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='precision',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# Best: 0.813378 using {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
    "\n",
    "\n",
    "# training svm model to maximize F1\n",
    "from sklearn import svm\n",
    "clfsvm = svm.SVC(kernel='linear', class_weight ={0: 1.417, 1: 1}, probability=True)# Linear Kernel\n",
    "clfsvm.fit(X_train, y_train)\n",
    "yhat = clfsvm.predict_proba(X_test)\n",
    "probs = yhat[:, 1] # predict_proba \n",
    "decisions = clfsvm.decision_function(X_test) #using decision function\n",
    "thresholds = np.arange(-0.5, 0.5, 0.001) # varying threshold values\n",
    "thresholds = list(thresholds) \n",
    "def to_labels(pos_probs, threshold):\n",
    "    return(pos_probs >= threshold).astype('int')\n",
    "# scores = [f1_score(y_test, to_labels(probs, t), average='weighted') for t in thresholds] # for predict_proba\n",
    "scores = [f1_score(y_test, to_labels(decisions, t), average='weighted') for t in thresholds] # for decision function\n",
    "argmax = np.argmax(scores) # find highest f1\n",
    "print(\"Best Threshold: {:.2f}, best weighted F1: {:.2f}\".format(thresholds[argmax], 100*scores[argmax])) # print threshold for highest f1\n",
    "predictions = to_labels(decisions, 0)\n",
    "print(f1_score(y_test, predictions, average=\"weighted\"))\n",
    "\n",
    "\n",
    "# original f1 \n",
    "print(\"Test accuracy using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*clfsvm.score(X_test, y_test)))\n",
    "print(\"Weighted F1 using review sentiment and summary sentiment: {:.2f}\".format(100*f1_score(y_test, \n",
    "             clfsvm.predict(X_test), \n",
    "             average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-37730da7a9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../datasets/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"amazon-id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#use sentiment model to get summary & review test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#5. TESTING MODEL \n",
    "#*****************************************************\n",
    "# pred = clfsvm.predict(X_test)\n",
    "# print(decisions)\n",
    "# print(pred)\n",
    "# # clearly decision < 0 implies class value = 1, 0 otherwise \n",
    "\n",
    "\n",
    "#test data \n",
    "df = pd.read_csv(\"../datasets/test.csv\")\n",
    "products = df[\"amazon-id\"]\n",
    "#use sentiment model to get summary & review test data \n",
    "summary_data = vect2.transform(df['summary'].values.astype('U'))\n",
    "review_data = vect1.transform(df['reviewText'].values.astype('U'))\n",
    "\n",
    "#generate predictions\n",
    "summary_predictions = summary_clf.predict(summary_data)\n",
    "review_predictions = review_clf.predict(review_data)\n",
    "\n",
    "#format avg. sentiment for reviews and summaries\n",
    "review_predictions, summary_predictions = list(review_predictions), list(summary_predictions)\n",
    "amz_review_sentiments, amz_summary_sentiments = {}, {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in amz_review_sentiments:\n",
    "        amz_review_sentiments[products[i]] = [review_predictions[i]]\n",
    "        amz_summary_sentiments[products[i]] = [summary_predictions[i]]\n",
    "    else:\n",
    "        amz_review_sentiments[products[i]].append(review_predictions[i])\n",
    "        amz_summary_sentiments[products[i]].append(summary_predictions[i])\n",
    "\n",
    "avg_review_sentiments = [np.average(amz_review_sentiments[prod]) for prod in amz_review_sentiments]\n",
    "avg_summary_sentiments = [np.average(amz_summary_sentiments[prod]) for prod in amz_summary_sentiments]\n",
    "\n",
    "avg_review_sentiments = [[score] for score in avg_review_sentiments]\n",
    "avg_summary_sentiments = [[score] for score in avg_summary_sentiments]\n",
    "\n",
    "#format sales\n",
    "sales_ranks = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in sales_ranks:\n",
    "        sales_ranks[products[i]] = [df['salesRank'][i]]\n",
    "    else:\n",
    "        sales_ranks[products[i]].append(df['salesRank'][i])\n",
    "\n",
    "avg_sales_ranks = [[np.average(sales_ranks[prod])] for prod in sales_ranks]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "scaler = StandardScaler() # 73.6 weighted F1\n",
    "\n",
    "scaler.fit(avg_sales_ranks)\n",
    "avg_sales_ranks = scaler.transform(avg_sales_ranks)\n",
    "\n",
    "#format prices\n",
    "prices = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in prices:\n",
    "        prices[products[i]] = [df['price'][i]]\n",
    "    else:\n",
    "        prices[products[i]].append(df['price'][i])\n",
    "\n",
    "avg_prices = [[np.average(prices[prod])] for prod in prices]\n",
    "\n",
    "scaler.fit(avg_prices)\n",
    "avg_prices = scaler.transform(avg_prices)\n",
    "\n",
    "X = np.zeros((len(avg_review_sentiments), 4))\n",
    "for i in range(X.shape[0]):\n",
    "    X[i] = (avg_review_sentiments[i][0], avg_summary_sentiments[i][0], avg_sales_ranks[i][0], \n",
    "           avg_prices[i][0])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16643572\n",
      "                amazon-id  predictions\n",
      "0    -3827781478900123339            0\n",
      "1    -1146746308871643825            1\n",
      "2     7943165581472649995            1\n",
      "3     9108673782042818101            1\n",
      "4     6254356016991899485            1\n",
      "...                   ...          ...\n",
      "1167  4506115376437312142            0\n",
      "1168 -6988320743350098006            1\n",
      "1169 -3693875680135982463            1\n",
      "1170  -731073713917118219            1\n",
      "1171  3029504406721887445            1\n",
      "\n",
      "[1172 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Generating prediction matrix\n",
    "\n",
    "#this will take some time, so don't fret\n",
    "predictions = clfsvm.predict(X)\n",
    "d = {'amazon-id': [], 'predictions': []}\n",
    "\n",
    "#consolidating product amazon-ids\n",
    "print(len(products)*len(predictions))\n",
    "prod = []\n",
    "for i in range(len(products)):\n",
    "    isNot = True \n",
    "    for j in range(len(prod)):\n",
    "        if products[i] == prod[j]:\n",
    "            isNot = False\n",
    "    if isNot:\n",
    "        prod.append(products[i])\n",
    "        \n",
    "#alligning \"awesomeness\" rating with amazon-id -- the ids are listed in the order they are found in the original data \n",
    "for i in range(len(predictions)):\n",
    "    d.get('amazon-id').append(prod[i])\n",
    "    d.get('predictions').append(predictions[i])\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df)\n",
    "# df.to_csv('test_predictions',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
