{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk \n",
    "import sklearn.model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.ensemble import GradientBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import time\n",
    "\n",
    "#  # For Alex's machine\n",
    "# df = pd.read_csv(\"Data/Train.csv\")\n",
    "\n",
    "# For Gokul's machine\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "#extract the review summary columm\n",
    "#print(df[\"summary\"], df[\"overall\"])\n",
    "\n",
    "#array of all the summaries\n",
    "\n",
    "og_summaries = df['summary']\n",
    "summaries = df[\"summary\"]\n",
    "\n",
    "#array of the overalls\n",
    "overall = df[\"overall\"]\n",
    "\n",
    "#array of product nums\n",
    "products = df[\"amazon-id\"]\n",
    "\n",
    "og_amazon_reviews = df['reviewText']\n",
    "amazon_reviews = df['reviewText']\n",
    "\n",
    "#array of artists \n",
    "artist_arr = df['artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting IMDB movie reviews\n",
    "\n",
    "# For Gokul's machine\n",
    "# moviesdf = pd.read_csv(\"./labeledTrainData.tsv\", delimiter = \"\\t\")\n",
    "# moviesdf = pd.read_csv('Data/imdb_data.csv')\n",
    "# moviesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiments = [int(sentiment=='positive') for sentiment in moviesdf['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ratings associated with reviews as indicators of sentiment\n",
    "review_sentiments = [int(overall[i] >= 5) for i in range(len(overall))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(amazon_reviews)):\n",
    "    if type(amazon_reviews[i])!=str:\n",
    "        amazon_reviews.pop(i)\n",
    "        review_sentiments.pop(i)\n",
    "print(set([type(r) for r in amazon_reviews]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews = moviesdf[\"review\"]\n",
    "#sentiment = moviesdf[\"sentiment\"]\n",
    "\n",
    "#create train test split\n",
    "x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(amazon_reviews, \n",
    "                                                                       review_sentiments, \n",
    "                                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 80.91740476704831\n",
      "Time taken: 4.71 seconds\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "vect = HashingVectorizer()\n",
    "\n",
    "x_train = vect.fit_transform(x_train)\n",
    "x_test = vect.transform(x_test)\n",
    "\n",
    "# We can experiment with different numbers of max iterations\n",
    "# 100 iters is default\n",
    "# iters = [1000]\n",
    "\n",
    "start = time.time()\n",
    "review_clf = LogisticRegression(max_iter=500)\n",
    "review_clf.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Test accuracy: {}\".format(100*review_clf.score(x_test, y_test)))\n",
    "print(\"Time taken: {:.2f} seconds\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "summary_sentiments = [int(overall[i] >= 5) for i in range(len(overall))]\n",
    "for i in range(len(summaries)):\n",
    "    if type(summaries[i])!=str:\n",
    "        summaries.pop(i)\n",
    "        summary_sentiments.pop(i)\n",
    "print(set([type(s) for s in summaries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = sk.model_selection.train_test_split(summaries, \n",
    "                                                                       summary_sentiments, \n",
    "                                                                       random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 77.88219197810903\n",
      "Time taken: 0.88 seconds\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "x_train = vect.fit_transform(x_train)\n",
    "x_test = vect.transform(x_test)\n",
    "\n",
    "# We can experiment with different numbers of max iterations\n",
    "# 100 iters is default\n",
    "# iters = [1000]\n",
    "\n",
    "start = time.time()\n",
    "summary_clf = LogisticRegression(max_iter=500)\n",
    "summary_clf.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Test accuracy: {}\".format(100*summary_clf.score(x_test, y_test)))\n",
    "print(\"Time taken: {:.2f} seconds\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this to classify shit\n",
    "\n",
    "summary_data = vect.transform(df['summary'].values.astype('U'))\n",
    "review_data = vect.transform(df['reviewText'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111098, 1048576)\n"
     ]
    }
   ],
   "source": [
    "print(review_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_predictions = summary_clf.predict(summary_data)\n",
    "review_predictions = review_clf.predict(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy analysis\n",
    "\n",
    "def getAccuracy(texts, preds):\n",
    "    total = len(texts)\n",
    "    t = 0\n",
    "    for i in range(total):\n",
    "        if (overall[i] >= 4 and preds[i] == 1) or (overall[i] < 4 and preds[i] == 0):\n",
    "            t+=1\n",
    "    return t/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of summary sentiment classifier on Amazon summaries: 0.87\n",
      "Accuracy of review sentiment classifier on Amazon reviews: 0.86\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of summary sentiment classifier on Amazon summaries: {:.2f}\".format(getAccuracy(summaries, summary_predictions)))\n",
    "print(\"Accuracy of review sentiment classifier on Amazon reviews: {:.2f}\".format(getAccuracy(amazon_reviews, review_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll now train three classifiers:\n",
    "# 1. Using just avg. summary sentiment as a feature\n",
    "# 2. Using just avg. review sentiment as a feature\n",
    "# 3. Using both (1) and (2) as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in targets:\n",
    "        targets[products[i]] = [overall[i]]\n",
    "    else:\n",
    "        targets[products[i]].append(overall[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [int(np.average(targets[prod]) > 4.5) for prod in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_predictions, summary_predictions = list(review_predictions), list(summary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_review_sentiments, amz_summary_sentiments = {}, {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in amz_review_sentiments:\n",
    "        amz_review_sentiments[products[i]] = [review_predictions[i]]\n",
    "        amz_summary_sentiments[products[i]] = [summary_predictions[i]]\n",
    "    else:\n",
    "        amz_review_sentiments[products[i]].append(review_predictions[i])\n",
    "        amz_summary_sentiments[products[i]].append(summary_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_review_sentiments = [np.average(amz_review_sentiments[prod]) for prod in amz_review_sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_summary_sentiments = [np.average(amz_summary_sentiments[prod]) for prod in amz_summary_sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_review_sentiments = [[score] for score in avg_review_sentiments]\n",
    "avg_summary_sentiments = [[score] for score in avg_summary_sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(avg_summary_sentiments, targets, random_state=1)\n",
    "\n",
    "\n",
    "#train model\n",
    "summary_only_clf = LogisticRegression()\n",
    "summary_only_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using summary sentiment only: 73.18\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy using summary sentiment only: {:.2f}\".format(100*summary_only_clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulsrin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(avg_review_sentiments, targets, random_state=1)\n",
    "\n",
    "\n",
    "#train model\n",
    "review_only_clf = LogisticRegression()\n",
    "review_only_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy using review sentiment only: 74.43\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy using review sentiment only: {:.2f}\".format(100*review_only_clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we develop the artist feature with just summary predictions\n",
    "artist = {}\n",
    "for i in range(len(summary_predictions)):\n",
    "    if artist.get(artist_arr[i]) == None:\n",
    "        artist[artist_arr[i]] = [summary_predictions]\n",
    "    else:\n",
    "        artist.get(artist_arr[i]).append(summary_predictions)\n",
    "for a in artist:\n",
    "    artist[a] = np.average(artist.get(a))\n",
    "    print('aritst:',artist,\"; score:\",artist.get(a))\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(avg_review_sentiments), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    X[i] = (avg_review_sentiments[i][0], avg_summary_sentiments[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [[t] for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.asarray(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "for train_idx, test_idx in kf.split(targets):\n",
    "    y_train, y_test = targets[train_idx], targets[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([s for s in targets if s[0]==1]))\n",
    "print(len([s for s in targets if s[0]==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(6181/4362)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(X, targets, random_state=1)\n",
    "\n",
    "\n",
    "#train model\n",
    "review_and_summary_clf = SVC(kernel='linear', class_weight = {0: 1.417, 1:1})\n",
    "# review_and_summary_clf = AdaBoostClassifier(SVC(probability=True,kernel='linear', class_weight = {0: 1.417, 1:1}),n_estimators=10, random_state=1)\n",
    "review_and_summary_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy using review sentiment and summary sentiment: {:.2f}\".format(100*review_and_summary_clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted F1 using review sentiment and summary sentiment: {:.2f}\".format(100*f1_score(Y_test, \n",
    "             review_and_summary_clf.predict(X_test), \n",
    "             average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_ranks = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in sales_ranks:\n",
    "        sales_ranks[products[i]] = [df['salesRank'][i]]\n",
    "    else:\n",
    "        sales_ranks[products[i]].append(df['salesRank'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sales_ranks = [[np.average(sales_ranks[prod])] for prod in sales_ranks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer, QuantileTransformer, PowerTransformer\n",
    "scaler = StandardScaler() # 73.6 weighted F1\n",
    "# scaler = MinMaxScaler() # 73.6 weighted F1\n",
    "# scaler = MaxAbsScaler() # 73.6 weighted F1\n",
    "# scaler = RobustScaler() # 73.6 weighted F1\n",
    "# scaler = Normalizer() # 73.48 weighted F1\n",
    "# scaler = QuantileTransformer() # 73.48 weighted F1\n",
    "# scaler = PowerTransformer() # 73.48 weighted F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(avg_sales_ranks)\n",
    "avg_sales_ranks = scaler.transform(avg_sales_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(avg_review_sentiments), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X.shape[0]):\n",
    "    X[i] = (avg_review_sentiments[i][0], avg_summary_sentiments[i][0], avg_sales_ranks[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "for train_idx, test_idx in kf.split(targets):\n",
    "    y_train, y_test = targets[train_idx], targets[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_summary_sales_clf = SVC(kernel='linear', class_weight = {0: 1.417, 1:1})\n",
    "review_summary_sales_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy using review sentiment, summary sentiment, and sales rank: {:.2f}\".format(100*review_summary_sales_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted F1 using review sentiment, summary sentiment, and sales rank: {:.2f}\".format(100*f1_score(y_test, \n",
    "             review_summary_sales_clf.predict(X_test), \n",
    "             average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to get better F1 score\n",
    "# yhat = review_summary_sales_clf.predict_proba(X_test)\n",
    "# probs = yhat[:,1]\n",
    "# thresholds = np.arrange(0,1,0.001)\n",
    "# def to_labels(pos_prob, threshold):\n",
    "#     return (pos_prob >= threshold).astype('int')\n",
    "# scores = [f1_score(y_test, to_labels(probs, t), average ='weighted') for t in thresholds]\n",
    "# argmax = np.argmax(scores)\n",
    "# print('Best threshold: {:.2f}, Best weighted {:.2f}'.format(thresholds[argmax], scores[argmax]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = {}\n",
    "for i in range(len(products)):\n",
    "    if products[i] not in prices:\n",
    "        prices[products[i]] = [df['price'][i]]\n",
    "    else:\n",
    "        prices[products[i]].append(df['price'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prices = [[np.average(prices[prod])] for prod in prices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(avg_prices)\n",
    "avg_prices = scaler.transform(avg_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(avg_review_sentiments), 4))\n",
    "for i in range(X.shape[0]):\n",
    "    X[i] = (avg_review_sentiments[i][0], avg_summary_sentiments[i][0], avg_sales_ranks[i][0], \n",
    "           avg_prices[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_idx, test_idx in kf.split(X):\n",
    "#     X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "# for train_idx, test_idx in kf.split(targets):\n",
    "#     y_train, y_test = targets[train_idx], targets[test_idx]\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(X, targets, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_summary_sales_price_clf = SVC( kernel='linear',class_weight = {0: 1.417, 1:1})\n",
    "review_summary_sales_price_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*review_summary_sales_price_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted F1 using review sentiment, summary sentiment, sales rank, and price: {:.2f}\".format(100*f1_score(y_test, \n",
    "             review_summary_sales_price_clf.predict(X_test), \n",
    "             average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
